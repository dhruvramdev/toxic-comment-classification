{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 8)\n",
      "(153164, 2)\n",
      "(153164, 7)\n"
     ]
    }
   ],
   "source": [
    "train = pandas.read_csv('./dataset/train.csv')\n",
    "test = pandas.read_csv('./dataset/test.csv')\n",
    "test_labels = pandas.read_csv('./dataset/test_labels.csv')\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
       "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
       "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat',\n",
       "       'insult', 'identity_hate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0005c987bdfc9d4b</td>\n",
       "      <td>Hey... what is it..\\n@ | talk .\\nWhat is it......</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0007e25b2121310b</td>\n",
       "      <td>Bye! \\n\\nDon't look, come or think of comming ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>001810bf8c45bf5f</td>\n",
       "      <td>You are gay or antisemmitian? \\n\\nArchangel WH...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>00190820581d90ce</td>\n",
       "      <td>FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>001956c382006abd</td>\n",
       "      <td>I'm Sorry \\n\\nI'm sorry I screwed around with ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>001dc38a83d420cf</td>\n",
       "      <td>GET FUCKED UP. GET FUCKEEED UP.  GOT A DRINK T...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0020e7119b96eeeb</td>\n",
       "      <td>Stupid peace of shit stop deleting my stuff as...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0020fd96ed3b8c8b</td>\n",
       "      <td>=Tony Sidaway is obviously a fistfuckee. He lo...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0021fe88bc4da3e6</td>\n",
       "      <td>My Band Page's deletion. You thought I was gon...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>002264ea4d5f2887</td>\n",
       "      <td>Why can't you believe how fat Artie is? Did yo...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0028d62e8a5629aa</td>\n",
       "      <td>All of my edits are good.  Cunts like you who ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>003217c3eb469ba9</td>\n",
       "      <td>Hi! I am back again!\\nLast warning!\\nStop undo...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0036621e4c7e10b5</td>\n",
       "      <td>Would you both shut up, you don't run wikipedi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>00472b8e2d38d1ea</td>\n",
       "      <td>A pair of jew-hating weiner nazi schmucks.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>005f59485fcddeb0</td>\n",
       "      <td>\"\\n\\nSORRY PUCK BUT NO ONE EVER SAID DICK WAS ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>00637960a7ec3436</td>\n",
       "      <td>\"\\n\\nUNBLOCK ME OR I'LL GET MY LAWYERS ON TO Y...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>00686325bcc16080</td>\n",
       "      <td>You should be fired, you're a moronic wimp who...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>006b94add72ed61c</td>\n",
       "      <td>I think that your a Fagget get a oife and burn...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>006e87872c8b370c</td>\n",
       "      <td>you are a stupid fuck \\n\\nand your mother's cu...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>007f1839ada915e6</td>\n",
       "      <td>Your blatant POV pushing \\n\\nNeither of you gu...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0082b5a7b4a67da2</td>\n",
       "      <td>Give me a permanat block raseac....!!! remembe...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>0086998b34865f93</td>\n",
       "      <td>Fuck you, block me, you faggot pussy!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>008e0818dde894fb</td>\n",
       "      <td>Kill all niggers. \\n\\nI have hard, that others...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>009371b0ef213487</td>\n",
       "      <td>Burn Deck \\n\\nIf that'd guy's burn deck is lik...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>0097dd5c29bf7a15</td>\n",
       "      <td>u r a tw@ fuck off u gay boy.U r smelly.Fuck u...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>00ab65775c601cf9</td>\n",
       "      <td>Atheism is full of bias shit</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>00afb4dec99a231f</td>\n",
       "      <td>Hey why you are spreading misconceptions and t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>00b77cb600c897b4</td>\n",
       "      <td>\"\\n\\nAnd you are? Let me know when you've craw...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>00be7dcac98dc95d</td>\n",
       "      <td>this user is such a worthless goddamn faggot f...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159253</th>\n",
       "      <td>fae97a014c011e3a</td>\n",
       "      <td>what do you mean \\n\\nwhy don't you keep your n...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159268</th>\n",
       "      <td>fb32b002bc46b830</td>\n",
       "      <td>Hi Bading \\nPutang ina mong bakla ka. Fuck you...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159274</th>\n",
       "      <td>fb4cbf4eeabe23d4</td>\n",
       "      <td>\"\\n\\nStudy some linguistics before you say som...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159281</th>\n",
       "      <td>fb726deec64157bd</td>\n",
       "      <td>LoL!! \\n\\nyou're GAY!! you will never know how...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159290</th>\n",
       "      <td>fb91faebc0197bd1</td>\n",
       "      <td>Hey alabamoy boy why dont you stick your head ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159298</th>\n",
       "      <td>fbb37645ecf5e403</td>\n",
       "      <td>, are you dumber than you look? asshole.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159312</th>\n",
       "      <td>fbf20e312cd4a78d</td>\n",
       "      <td>Walter Mercado \\n\\nAntonio, quite frankly, you...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159315</th>\n",
       "      <td>fbf8672ea3b4ddf7</td>\n",
       "      <td>http://www.nysun.com/article/23698 - public in...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159334</th>\n",
       "      <td>fc3a75b57f1f6923</td>\n",
       "      <td>Horse's ass \\n\\nSeriously, dude, what's that h...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159336</th>\n",
       "      <td>fc3efa2f6f025f6d</td>\n",
       "      <td>Oh, fuck off. The pansy Jew would just whine a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159342</th>\n",
       "      <td>fc4a76f9f0ecd189</td>\n",
       "      <td>Fuck off turd. Don't ever ban me again you cun...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159358</th>\n",
       "      <td>fc6d45d108129fc8</td>\n",
       "      <td>Goethean and me\\n\\nI would like you to know I ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159368</th>\n",
       "      <td>fc8f351add0fd065</td>\n",
       "      <td>\"\\n\\n Palin/Satan 2012 \\n\\nWow, what a surpris...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159378</th>\n",
       "      <td>fcb09a6d428bdb74</td>\n",
       "      <td>GO AHEAD AND FUCKING BAN ME ~ LIKE THAT WILL H...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159382</th>\n",
       "      <td>fcbc0c74d75584c2</td>\n",
       "      <td>shut up you goddamn assclown.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159386</th>\n",
       "      <td>fccf0939631ab7c8</td>\n",
       "      <td>Stop telling lies and trying to promote your p...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159394</th>\n",
       "      <td>fcf5a6ad5918f164</td>\n",
       "      <td>your boring \\n\\nand retarded two</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159398</th>\n",
       "      <td>fd0129fde97321cb</td>\n",
       "      <td>Why did that idiot revert the reversion I made...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159400</th>\n",
       "      <td>fd052883fa6a8697</td>\n",
       "      <td>Shalom \\n\\nSemite, get the fuck out of here. I...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159411</th>\n",
       "      <td>fd2f53aafe8eefcc</td>\n",
       "      <td>Fat piece of shit \\n\\nyou obese piece of shit....</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159423</th>\n",
       "      <td>fd68ef478b3dfd05</td>\n",
       "      <td>PS:  you're all middle-aged losers at home in ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159448</th>\n",
       "      <td>fdc92e571d39e7e1</td>\n",
       "      <td>Yeah i no it sucks.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159449</th>\n",
       "      <td>fdce660ddcd6d7ca</td>\n",
       "      <td>I think he is a gay fag!!!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159478</th>\n",
       "      <td>feb5637c531f933d</td>\n",
       "      <td>\"\\nThank you. Given the misuse of tools here a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159493</th>\n",
       "      <td>fef142420a215b90</td>\n",
       "      <td>FUCKING FAGGOT \\n\\nLOLWAT.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159494</th>\n",
       "      <td>fef4cf7ba0012866</td>\n",
       "      <td>\"\\n\\n our previous conversation \\n\\nyou fuckin...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159514</th>\n",
       "      <td>ff39a2895fc3b40e</td>\n",
       "      <td>YOU ARE A MISCHIEVIOUS PUBIC HAIR</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159541</th>\n",
       "      <td>ffa33d3122b599d6</td>\n",
       "      <td>Your absurd edits \\n\\nYour absurd edits on gre...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159546</th>\n",
       "      <td>ffb47123b2d82762</td>\n",
       "      <td>\"\\n\\nHey listen don't you ever!!!! Delete my e...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159554</th>\n",
       "      <td>ffbdbb0483ed0841</td>\n",
       "      <td>and i'm going to keep posting the stuff u dele...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15294 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "6       0002bcb3da6cb337       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK   \n",
       "12      0005c987bdfc9d4b  Hey... what is it..\\n@ | talk .\\nWhat is it......   \n",
       "16      0007e25b2121310b  Bye! \\n\\nDon't look, come or think of comming ...   \n",
       "42      001810bf8c45bf5f  You are gay or antisemmitian? \\n\\nArchangel WH...   \n",
       "43      00190820581d90ce           FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!   \n",
       "44      001956c382006abd  I'm Sorry \\n\\nI'm sorry I screwed around with ...   \n",
       "51      001dc38a83d420cf  GET FUCKED UP. GET FUCKEEED UP.  GOT A DRINK T...   \n",
       "55      0020e7119b96eeeb  Stupid peace of shit stop deleting my stuff as...   \n",
       "56      0020fd96ed3b8c8b  =Tony Sidaway is obviously a fistfuckee. He lo...   \n",
       "58      0021fe88bc4da3e6  My Band Page's deletion. You thought I was gon...   \n",
       "59      002264ea4d5f2887  Why can't you believe how fat Artie is? Did yo...   \n",
       "65      0028d62e8a5629aa  All of my edits are good.  Cunts like you who ...   \n",
       "79      003217c3eb469ba9  Hi! I am back again!\\nLast warning!\\nStop undo...   \n",
       "86      0036621e4c7e10b5  Would you both shut up, you don't run wikipedi...   \n",
       "105     00472b8e2d38d1ea         A pair of jew-hating weiner nazi schmucks.   \n",
       "151     005f59485fcddeb0  \"\\n\\nSORRY PUCK BUT NO ONE EVER SAID DICK WAS ...   \n",
       "159     00637960a7ec3436  \"\\n\\nUNBLOCK ME OR I'LL GET MY LAWYERS ON TO Y...   \n",
       "168     00686325bcc16080  You should be fired, you're a moronic wimp who...   \n",
       "176     006b94add72ed61c  I think that your a Fagget get a oife and burn...   \n",
       "181     006e87872c8b370c  you are a stupid fuck \\n\\nand your mother's cu...   \n",
       "201     007f1839ada915e6  Your blatant POV pushing \\n\\nNeither of you gu...   \n",
       "206     0082b5a7b4a67da2  Give me a permanat block raseac....!!! remembe...   \n",
       "211     0086998b34865f93              Fuck you, block me, you faggot pussy!   \n",
       "218     008e0818dde894fb  Kill all niggers. \\n\\nI have hard, that others...   \n",
       "231     009371b0ef213487  Burn Deck \\n\\nIf that'd guy's burn deck is lik...   \n",
       "238     0097dd5c29bf7a15  u r a tw@ fuck off u gay boy.U r smelly.Fuck u...   \n",
       "268     00ab65775c601cf9                       Atheism is full of bias shit   \n",
       "278     00afb4dec99a231f  Hey why you are spreading misconceptions and t...   \n",
       "286     00b77cb600c897b4  \"\\n\\nAnd you are? Let me know when you've craw...   \n",
       "295     00be7dcac98dc95d  this user is such a worthless goddamn faggot f...   \n",
       "...                  ...                                                ...   \n",
       "159253  fae97a014c011e3a  what do you mean \\n\\nwhy don't you keep your n...   \n",
       "159268  fb32b002bc46b830  Hi Bading \\nPutang ina mong bakla ka. Fuck you...   \n",
       "159274  fb4cbf4eeabe23d4  \"\\n\\nStudy some linguistics before you say som...   \n",
       "159281  fb726deec64157bd  LoL!! \\n\\nyou're GAY!! you will never know how...   \n",
       "159290  fb91faebc0197bd1  Hey alabamoy boy why dont you stick your head ...   \n",
       "159298  fbb37645ecf5e403           , are you dumber than you look? asshole.   \n",
       "159312  fbf20e312cd4a78d  Walter Mercado \\n\\nAntonio, quite frankly, you...   \n",
       "159315  fbf8672ea3b4ddf7  http://www.nysun.com/article/23698 - public in...   \n",
       "159334  fc3a75b57f1f6923  Horse's ass \\n\\nSeriously, dude, what's that h...   \n",
       "159336  fc3efa2f6f025f6d  Oh, fuck off. The pansy Jew would just whine a...   \n",
       "159342  fc4a76f9f0ecd189  Fuck off turd. Don't ever ban me again you cun...   \n",
       "159358  fc6d45d108129fc8  Goethean and me\\n\\nI would like you to know I ...   \n",
       "159368  fc8f351add0fd065  \"\\n\\n Palin/Satan 2012 \\n\\nWow, what a surpris...   \n",
       "159378  fcb09a6d428bdb74  GO AHEAD AND FUCKING BAN ME ~ LIKE THAT WILL H...   \n",
       "159382  fcbc0c74d75584c2                      shut up you goddamn assclown.   \n",
       "159386  fccf0939631ab7c8  Stop telling lies and trying to promote your p...   \n",
       "159394  fcf5a6ad5918f164                   your boring \\n\\nand retarded two   \n",
       "159398  fd0129fde97321cb  Why did that idiot revert the reversion I made...   \n",
       "159400  fd052883fa6a8697  Shalom \\n\\nSemite, get the fuck out of here. I...   \n",
       "159411  fd2f53aafe8eefcc  Fat piece of shit \\n\\nyou obese piece of shit....   \n",
       "159423  fd68ef478b3dfd05  PS:  you're all middle-aged losers at home in ...   \n",
       "159448  fdc92e571d39e7e1                                Yeah i no it sucks.   \n",
       "159449  fdce660ddcd6d7ca                         I think he is a gay fag!!!   \n",
       "159478  feb5637c531f933d  \"\\nThank you. Given the misuse of tools here a...   \n",
       "159493  fef142420a215b90                         FUCKING FAGGOT \\n\\nLOLWAT.   \n",
       "159494  fef4cf7ba0012866  \"\\n\\n our previous conversation \\n\\nyou fuckin...   \n",
       "159514  ff39a2895fc3b40e                  YOU ARE A MISCHIEVIOUS PUBIC HAIR   \n",
       "159541  ffa33d3122b599d6  Your absurd edits \\n\\nYour absurd edits on gre...   \n",
       "159546  ffb47123b2d82762  \"\\n\\nHey listen don't you ever!!!! Delete my e...   \n",
       "159554  ffbdbb0483ed0841  and i'm going to keep posting the stuff u dele...   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "6           1             1        1       0       1              0  \n",
       "12          1             0        0       0       0              0  \n",
       "16          1             0        0       0       0              0  \n",
       "42          1             0        1       0       1              1  \n",
       "43          1             0        1       0       1              0  \n",
       "44          1             0        0       0       0              0  \n",
       "51          1             0        1       0       0              0  \n",
       "55          1             1        1       0       1              0  \n",
       "56          1             0        1       0       1              0  \n",
       "58          1             0        1       0       0              0  \n",
       "59          1             0        0       0       0              0  \n",
       "65          1             0        1       0       1              0  \n",
       "79          1             0        0       1       0              0  \n",
       "86          1             0        0       0       1              0  \n",
       "105         1             0        1       0       1              1  \n",
       "151         1             0        0       0       0              0  \n",
       "159         1             0        0       0       0              0  \n",
       "168         1             0        0       0       1              0  \n",
       "176         1             0        1       1       1              1  \n",
       "181         1             1        1       0       1              0  \n",
       "201         1             0        1       0       0              0  \n",
       "206         1             0        0       0       0              0  \n",
       "211         1             0        1       0       1              0  \n",
       "218         1             0        1       0       1              1  \n",
       "231         1             0        1       0       1              0  \n",
       "238         1             0        1       0       1              1  \n",
       "268         1             0        0       0       0              0  \n",
       "278         1             0        0       0       0              0  \n",
       "286         1             0        0       0       0              0  \n",
       "295         1             0        1       0       1              0  \n",
       "...       ...           ...      ...     ...     ...            ...  \n",
       "159253      1             0        1       0       0              0  \n",
       "159268      1             0        1       0       1              0  \n",
       "159274      1             0        0       0       0              0  \n",
       "159281      1             1        1       0       1              1  \n",
       "159290      1             0        1       0       1              0  \n",
       "159298      1             0        1       0       1              0  \n",
       "159312      1             1        1       0       1              0  \n",
       "159315      1             0        0       0       0              0  \n",
       "159334      1             0        1       0       0              0  \n",
       "159336      1             0        1       0       1              1  \n",
       "159342      1             0        1       0       1              0  \n",
       "159358      1             0        0       0       0              0  \n",
       "159368      1             0        1       0       1              0  \n",
       "159378      1             0        1       0       1              0  \n",
       "159382      1             0        1       0       1              0  \n",
       "159386      1             0        0       0       0              0  \n",
       "159394      1             0        0       0       0              0  \n",
       "159398      1             0        0       0       0              0  \n",
       "159400      1             1        1       1       1              1  \n",
       "159411      1             0        1       0       1              0  \n",
       "159423      1             0        0       0       0              0  \n",
       "159448      1             0        0       0       0              0  \n",
       "159449      1             0        0       0       0              1  \n",
       "159478      1             0        0       0       0              0  \n",
       "159493      1             0        1       0       1              0  \n",
       "159494      1             0        1       0       1              1  \n",
       "159514      1             0        0       0       1              0  \n",
       "159541      1             0        1       0       1              0  \n",
       "159546      1             0        0       0       1              0  \n",
       "159554      1             0        1       0       1              0  \n",
       "\n",
       "[15294 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['toxic'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['comment_text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_regex = r'[a-zA-Z0-9]+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(X, classifier):\n",
    "    test_cols = [ 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "    roc_aoc_scores = []\n",
    "    \n",
    "    for eval_col in test_cols:\n",
    "#         print(\"FIT \", eval_col)\n",
    "        y = train[eval_col]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y,  test_size=0.3, random_state=101)\n",
    "\n",
    "        clf = classifier().fit(X_train, y_train)\n",
    "        predicted= clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "        roc_aoc_scores.append(metrics.roc_auc_score(y_test, predicted))\n",
    "    \n",
    "    print(\"Score :\" , np.mean(np.array(roc_aoc_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = RegexpTokenizer(token_regex)\n",
    "cv = CountVectorizer(lowercase=False, stop_words='english', ngram_range = (1,1), tokenizer = token.tokenize)\n",
    "text_cv = cv.fit_transform(train['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LemmaTokenizer(object):\n",
    "    def __init__(self, token_regex):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "        self.tokenizer = RegexpTokenizer(token_regex).tokenize\n",
    "    def tokenize(self, articles):\n",
    "#         print(articles)\n",
    "#         print(token.tokenize(articles))\n",
    "        return [self.wnl.lemmatize(t) for t in self.tokenizer(articles)]\n",
    "\n",
    "lemma = LemmaTokenizer(token_regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LemmaPOSTokenizer(object):\n",
    "    def __init__(self, token_regex):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "        self.tokenizer = RegexpTokenizer(token_regex).tokenize\n",
    "        \n",
    "        self.tag_dict = {\n",
    "            \"J\": wordnet.ADJ,\n",
    "            \"N\": wordnet.NOUN,\n",
    "            \"V\": wordnet.VERB,\n",
    "            \"R\": wordnet.ADV\n",
    "        }\n",
    "        \n",
    "    def tokenize(self, articles):\n",
    "#         print(articles)\n",
    "#         print(self.tokenizer(articles))\n",
    "#         print(pos_tag(self.tokenizer(articles)))\n",
    "#         a = [self.wnl.lemmatize(t,  get_wordnet_pos(t)) for t in self.tokenizer(articles)]\n",
    "#         print(a)\n",
    "#         return a\n",
    "        return [self.wnl.lemmatize(t[0], self.tag_dict.get(t[1][0], wordnet.NOUN) ) for t in pos_tag(self.tokenizer(articles))]\n",
    "\n",
    "lemma_pos = LemmaPOSTokenizer(token_regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make', 'u'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "525.1412253379822\n"
     ]
    }
   ],
   "source": [
    "cv_lemma_pos = CountVectorizer(lowercase=False, stop_words='english', ngram_range = (1,1), tokenizer = lemma_pos.tokenize)\n",
    "\n",
    "start = time.time()\n",
    "text_cv_lemma_pos = cv_lemma_pos.fit_transform(train['comment_text'])\n",
    "end = time.time()\n",
    "print (end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.207603931427\n"
     ]
    }
   ],
   "source": [
    "cv_lemma = CountVectorizer(lowercase=False, stop_words='english', ngram_range = (1,1), tokenizer = lemma.tokenize)\n",
    "\n",
    "start = time.time()\n",
    "text_cv_lemma =cv_lemma.fit_transform(train['comment_text'])\n",
    "end = time.time()\n",
    "print (end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<159571x227490 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 4748387 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<159571x219000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 4727202 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_cv_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<159571x216623 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 4551942 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_cv_lemma_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "tf = TfidfVectorizer(lowercase=False, stop_words='english', ngram_range = (1,1), tokenizer = token.tokenize)\n",
    "\n",
    "text_tf = tf.fit_transform(train['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['far', 'make', 'u'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "560.5757603645325\n"
     ]
    }
   ],
   "source": [
    "tf_lemma_pos = CountVectorizer(lowercase=False, stop_words='english', ngram_range = (1,1), tokenizer = lemma_pos.tokenize)\n",
    "\n",
    "start = time.time()\n",
    "text_tf_lemma_pos = tf_lemma_pos.fit_transform(train['comment_text'])\n",
    "end = time.time()\n",
    "print (end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.17615747451782\n"
     ]
    }
   ],
   "source": [
    "tf_lemma = CountVectorizer(lowercase=False, stop_words='english', ngram_range = (1,1), tokenizer = lemma.tokenize)\n",
    "\n",
    "start = time.time()\n",
    "text_tf_lemma =tf_lemma.fit_transform(train['comment_text'])\n",
    "end = time.time()\n",
    "print (end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<159571x227490 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4748387 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<159571x219000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 4727202 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tf_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<159571x216623 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 4551942 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tf_lemma_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifierMNB():\n",
    "    return MultinomialNB()\n",
    "\n",
    "def classifierLSVC():\n",
    "    return SVC(probability = True)\n",
    "\n",
    "def classifierLR():\n",
    "    return LogisticRegression(C=4, dual=True ,solver='liblinear')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1\n",
      "Score : 0.8624565578633603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score : 0.939653879355482\n",
      "#2\n",
      "Score : 0.8616465869550839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score : 0.9386275720347369\n",
      "#3\n",
      "Score : 0.8593732824253507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score : 0.9409338925164135\n",
      "#4\n",
      "Score : 0.844086677142248\n",
      "Score : 0.9749997779762191\n",
      "#5\n",
      "Score : 0.8616465869550839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score : 0.9388777762250657\n",
      "#6\n",
      "Score : 0.8593732824253507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score : 0.9409502994387643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "print(\"#1\")\n",
    "training(text_cv, classifierMNB)\n",
    "training(text_cv, classifierLR)\n",
    "\n",
    "print(\"#2\")\n",
    "training(text_cv_lemma, classifierMNB)\n",
    "training(text_cv_lemma, classifierLR)\n",
    "\n",
    "print(\"#3\")\n",
    "training(text_cv_lemma_pos, classifierMNB)\n",
    "training(text_cv_lemma_pos, classifierLR)\n",
    "\n",
    "print(\"#4\")\n",
    "training(text_tf, classifierMNB)\n",
    "training(text_tf, classifierLR)\n",
    "\n",
    "print(\"#5\")\n",
    "training(text_tf_lemma, classifierMNB)\n",
    "training(text_tf_lemma, classifierLR)\n",
    "\n",
    "print(\"#6\")\n",
    "training(text_tf_lemma_pos, classifierMNB)\n",
    "training(text_tf_lemma_pos, classifierLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "print(\"#1\")\n",
    "training(text_cv, classifierLSVC)\n",
    "\n",
    "# print(\"#2\")\n",
    "# training(text_cv_lemma, classifierLSVC)\n",
    "\n",
    "# print(\"#3\")\n",
    "# training(text_cv_lemma_pos, classifierLSVC)\n",
    "\n",
    "# print(\"#4\")\n",
    "# training(text_tf, classifierLSVC)\n",
    "\n",
    "# print(\"#5\")\n",
    "# training(text_tf_lemma, classifierLSVC)\n",
    "\n",
    "# print(\"#6\")\n",
    "# training(text_tf_lemma_pos, classifierLSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(X, TEST ,classifier):\n",
    "    test_cols = [ 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "    roc_aoc_scores = []\n",
    "    df = pd.DataFrame()\n",
    "    df['id'] = test['id']\n",
    "    \n",
    "    for eval_col in test_cols:\n",
    "        print(\"FIT \", eval_col)\n",
    "        y = train[eval_col]\n",
    "\n",
    "        clf = classifier().fit(X, y)\n",
    "        \n",
    "        predicted= clf.predict_proba(TEST)[:,1]\n",
    "        df[eval_col] = predicted\n",
    "\n",
    "    return df\n",
    "\n",
    "def calc_score(test_submission):\n",
    "    test_cols = [ 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "    roc_aoc_scores = []\n",
    "    selection = test_labels['toxic'] != -1\n",
    "    \n",
    "    test_dataset = test_labels[selection]\n",
    "    predicted_dataset = test_submission[selection]\n",
    "    \n",
    "    for eval_col in test_cols:\n",
    "        roc_aoc_scores.append(metrics.roc_auc_score(test_dataset[eval_col], predicted_dataset[eval_col]))\n",
    "    \n",
    "    print(roc_aoc_scores)\n",
    "    print(\"Score :\" , np.mean(np.array(roc_aoc_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIT  toxic\n",
      "FIT  severe_toxic\n",
      "FIT  obscene\n",
      "FIT  threat\n",
      "FIT  insult\n",
      "FIT  identity_hate\n"
     ]
    }
   ],
   "source": [
    "df = create_submission(text_counts_tf, text_counts_tf_test, classifierLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.999436</td>\n",
       "      <td>0.155168</td>\n",
       "      <td>0.998686</td>\n",
       "      <td>0.028091</td>\n",
       "      <td>0.943338</td>\n",
       "      <td>0.243038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.004460</td>\n",
       "      <td>0.001217</td>\n",
       "      <td>0.001015</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.004197</td>\n",
       "      <td>0.001587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.036480</td>\n",
       "      <td>0.004995</td>\n",
       "      <td>0.016637</td>\n",
       "      <td>0.001604</td>\n",
       "      <td>0.023716</td>\n",
       "      <td>0.006046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.001371</td>\n",
       "      <td>0.000849</td>\n",
       "      <td>0.001366</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>0.001324</td>\n",
       "      <td>0.000147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.014229</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>0.004530</td>\n",
       "      <td>0.001244</td>\n",
       "      <td>0.005928</td>\n",
       "      <td>0.001523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
       "0  00001cee341fdb12  0.999436      0.155168  0.998686  0.028091  0.943338   \n",
       "1  0000247867823ef7  0.004460      0.001217  0.001015  0.000466  0.004197   \n",
       "2  00013b17ad220c46  0.036480      0.004995  0.016637  0.001604  0.023716   \n",
       "3  00017563c3f7919a  0.001371      0.000849  0.001366  0.001147  0.001324   \n",
       "4  00017695ad8997eb  0.014229      0.001501  0.004530  0.001244  0.005928   \n",
       "\n",
       "   identity_hate  \n",
       "0       0.243038  \n",
       "1       0.001587  \n",
       "2       0.006046  \n",
       "3       0.000147  \n",
       "4       0.001523  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('submission_tfidf_lr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9590566668686306, 0.9835660481836188, 0.9736424523539231, 0.9839533173088607, 0.9651417711882404, 0.9733629579691526]\n",
      "Score : 0.9731205356454043\n"
     ]
    }
   ],
   "source": [
    "calc_score(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
