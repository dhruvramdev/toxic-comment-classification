{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119989, 10)\n",
      "(153164, 4)\n",
      "(153164, 7)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('./preprocessed/train.csv')\n",
    "test = pd.read_csv('./preprocessed/test.csv')\n",
    "test_labels = pd.read_csv('./dataset/test_labels.csv')\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>comment_lemma</th>\n",
       "      <th>comment_stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Explanation Why the edits make under my userna...</td>\n",
       "      <td>explan whi the edit made under my usernam hard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D'aww ! He match this background colour I 'm s...</td>\n",
       "      <td>d'aww ! He match thi background colour I 'm se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hey man , I 'm really not try to edit war . It...</td>\n",
       "      <td>hey man , I 'm realli not tri to edit war . It...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>`` More I ca n't make any real suggestion on i...</td>\n",
       "      <td>`` more I ca n't make ani real suggest on impr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>You , sir , be my hero . Any chance you rememb...</td>\n",
       "      <td>you , sir , are my hero . ani chanc you rememb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "0             0        0       0       0              0   \n",
       "1             0        0       0       0              0   \n",
       "2             0        0       0       0              0   \n",
       "3             0        0       0       0              0   \n",
       "4             0        0       0       0              0   \n",
       "\n",
       "                                       comment_lemma  \\\n",
       "0  Explanation Why the edits make under my userna...   \n",
       "1  D'aww ! He match this background colour I 'm s...   \n",
       "2  Hey man , I 'm really not try to edit war . It...   \n",
       "3  `` More I ca n't make any real suggestion on i...   \n",
       "4  You , sir , be my hero . Any chance you rememb...   \n",
       "\n",
       "                                        comment_stem  \n",
       "0  explan whi the edit made under my usernam hard...  \n",
       "1  d'aww ! He match thi background colour I 'm se...  \n",
       "2  hey man , I 'm realli not tri to edit war . It...  \n",
       "3  `` more I ca n't make ani real suggest on impr...  \n",
       "4  you , sir , are my hero . ani chanc you rememb...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>comment_lemma</th>\n",
       "      <th>comment_stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "      <td>Yo bitch Ja Rule be more succesful then you 'l...</td>\n",
       "      <td>Yo bitch Ja rule is more succes then you 'll e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "      <td>== From RfC == The title be fine as it be , IMO .</td>\n",
       "      <td>== from rfc == the titl is fine as it is , imo .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "      <td>`` == Sources == * Zawe Ashton on Lapland — / ``</td>\n",
       "      <td>`` == sourc == * zaw ashton on lapland — / ``</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "      <td>: If you have a look back at the source , the ...</td>\n",
       "      <td>: If you have a look back at the sourc , the i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "      <td>I do n't anonymously edit article at all .</td>\n",
       "      <td>I do n't anonym edit articl at all .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  \\\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...   \n",
       "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...   \n",
       "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...   \n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...   \n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all.   \n",
       "\n",
       "                                       comment_lemma  \\\n",
       "0  Yo bitch Ja Rule be more succesful then you 'l...   \n",
       "1  == From RfC == The title be fine as it be , IMO .   \n",
       "2   `` == Sources == * Zawe Ashton on Lapland — / ``   \n",
       "3  : If you have a look back at the source , the ...   \n",
       "4         I do n't anonymously edit article at all .   \n",
       "\n",
       "                                        comment_stem  \n",
       "0  Yo bitch Ja rule is more succes then you 'll e...  \n",
       "1   == from rfc == the titl is fine as it is , imo .  \n",
       "2      `` == sourc == * zaw ashton on lapland — / ``  \n",
       "3  : If you have a look back at the sourc , the i...  \n",
       "4               I do n't anonym edit articl at all .  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>comment_lemma</th>\n",
       "      <th>comment_stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>cocksuck befor you piss around ON MY work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0005c987bdfc9d4b</td>\n",
       "      <td>Hey... what is it..\\n@ | talk .\\nWhat is it......</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hey ... what be it.. @ | talk . What be it ......</td>\n",
       "      <td>hey ... what is it.. @ | talk . what is it ......</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0007e25b2121310b</td>\n",
       "      <td>Bye! \\n\\nDon't look, come or think of comming ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bye ! Do n't look , come or think of comming b...</td>\n",
       "      <td>bye ! Do n't look , come or think of com back ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>001810bf8c45bf5f</td>\n",
       "      <td>You are gay or antisemmitian? \\n\\nArchangel WH...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>You be gay or antisemmitian ? Archangel WHite ...</td>\n",
       "      <td>you are gay or antisemmitian ? archangel white...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>00190820581d90ce</td>\n",
       "      <td>FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>FUCK YOUR FILTHY MOTHER IN THE ASS , DRY !</td>\n",
       "      <td>fuck your filthi mother IN the ass , dri !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                       comment_text  \\\n",
       "6   0002bcb3da6cb337       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK   \n",
       "12  0005c987bdfc9d4b  Hey... what is it..\\n@ | talk .\\nWhat is it......   \n",
       "16  0007e25b2121310b  Bye! \\n\\nDon't look, come or think of comming ...   \n",
       "42  001810bf8c45bf5f  You are gay or antisemmitian? \\n\\nArchangel WH...   \n",
       "43  00190820581d90ce           FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!   \n",
       "\n",
       "    toxic  severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "6       1             1        1       0       1              0   \n",
       "12      1             0        0       0       0              0   \n",
       "16      1             0        0       0       0              0   \n",
       "42      1             0        1       0       1              1   \n",
       "43      1             0        1       0       1              0   \n",
       "\n",
       "                                        comment_lemma  \\\n",
       "6        COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK   \n",
       "12  Hey ... what be it.. @ | talk . What be it ......   \n",
       "16  Bye ! Do n't look , come or think of comming b...   \n",
       "42  You be gay or antisemmitian ? Archangel WHite ...   \n",
       "43         FUCK YOUR FILTHY MOTHER IN THE ASS , DRY !   \n",
       "\n",
       "                                         comment_stem  \n",
       "6           cocksuck befor you piss around ON MY work  \n",
       "12  hey ... what is it.. @ | talk . what is it ......  \n",
       "16  bye ! Do n't look , come or think of com back ...  \n",
       "42  you are gay or antisemmitian ? archangel white...  \n",
       "43         fuck your filthi mother IN the ass , dri !  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['toxic'] == 1][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['comment_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_regex = r'[a-zA-Z0-9]+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(X, classifier):\n",
    "    test_cols = [ 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "    roc_aoc_scores = []\n",
    "    \n",
    "    for eval_col in test_cols:\n",
    "#         print(\"FIT \", eval_col)\n",
    "        y = train[eval_col]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y,  test_size=0.3, random_state=101)\n",
    "\n",
    "        clf = classifier().fit(X_train, y_train)\n",
    "        predicted= clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "        roc_aoc_scores.append(metrics.roc_auc_score(y_test, predicted))\n",
    "    \n",
    "    avg_score = np.mean(np.array(roc_aoc_scores))\n",
    "    print(\"Score :\" , avg_score)\n",
    "    return clf, avg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer(object):\n",
    "    def __init__(self, token_regex):\n",
    "        self.tokenizer = RegexpTokenizer(token_regex).tokenize\n",
    "    def tokenize(self, articles):\n",
    "        return self.tokenizer(articles)\n",
    "\n",
    "simple = Tokenizer(token_regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PorterStemTokenizer(object):\n",
    "    def __init__(self, token_regex):\n",
    "        self.stemmer = PorterStemmer()\n",
    "        self.tokenizer = RegexpTokenizer(token_regex).tokenize\n",
    "    def tokenize(self, articles):\n",
    "        return [self.stemmer.stem(t) for t in self.tokenizer(articles)]\n",
    "\n",
    "stem = PorterStemTokenizer(token_regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LemmaTokenizer(object):\n",
    "    def __init__(self, token_regex):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "        self.tokenizer = RegexpTokenizer(token_regex).tokenize\n",
    "    def tokenize(self, articles):\n",
    "#         print(articles)\n",
    "#         print(token.tokenize(articles))\n",
    "        return [self.wnl.lemmatize(t) for t in self.tokenizer(articles)]\n",
    "\n",
    "lemma = LemmaTokenizer(token_regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LemmaPOSTokenizer(object):\n",
    "    def __init__(self, token_regex):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "        self.tokenizer = RegexpTokenizer(token_regex).tokenize\n",
    "        \n",
    "        self.tag_dict = {\n",
    "            \"J\": wordnet.ADJ,\n",
    "            \"N\": wordnet.NOUN,\n",
    "            \"V\": wordnet.VERB,\n",
    "            \"R\": wordnet.ADV\n",
    "        }\n",
    "        \n",
    "    def tokenize(self, articles):\n",
    "#         print(articles)\n",
    "#         print(self.tokenizer(articles))\n",
    "#         print(pos_tag(self.tokenizer(articles)))\n",
    "#         a = [self.wnl.lemmatize(t,  get_wordnet_pos(t)) for t in self.tokenizer(articles)]\n",
    "#         print(a)\n",
    "#         return a\n",
    "        return [self.wnl.lemmatize(t[0], self.tag_dict.get(t[1][0], wordnet.NOUN) ) for t in pos_tag(self.tokenizer(articles))]\n",
    "\n",
    "lemma_pos = LemmaPOSTokenizer(token_regex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_lemma_pos = CountVectorizer(lowercase=False, stop_words='english', ngram_range = (1,1), tokenizer = lemma_pos.tokenize)\n",
    "\n",
    "start = time.time()\n",
    "text_cv_lemma_pos = cv_lemma_pos.fit_transform(train['comment_text'])\n",
    "end = time.time()\n",
    "print (end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_lemma = CountVectorizer(lowercase=False, stop_words='english', ngram_range = (1,1), tokenizer = lemma.tokenize)\n",
    "\n",
    "start = time.time()\n",
    "text_cv_lemma =cv_lemma.fit_transform(train['comment_text'])\n",
    "end = time.time()\n",
    "print (end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_text = train['comment_text']\n",
    "# training_text = train['comment_text'][:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With Regex Tokenizer\n",
    "tf = TfidfVectorizer(ngram_range = (1,2),  strip_accents='unicode', tokenizer = simple.tokenize, max_features=80000)\n",
    "text_tf = tf.fit_transform(training_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score : 0.9769499633715956\n"
     ]
    }
   ],
   "source": [
    "def clf():\n",
    "    return LogisticRegression(C=2, solver='lbfgs')\n",
    "trained_clf, score = training(text_tf, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<159571x12364848 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 21162991 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<159571x80000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 13169732 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score : 0.9790874467858717\n"
     ]
    }
   ],
   "source": [
    "def clf():\n",
    "    return LogisticRegression(C=4, solver='lbfgs', max_iter=1000)\n",
    "trained_clf, score = training(text_tf, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score : 0.9790874467858717\n"
     ]
    }
   ],
   "source": [
    "def clf():\n",
    "    return LogisticRegression(C=4, solver='lbfgs', max_iter=500)\n",
    "trained_clf, score = training(text_tf, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score : 0.978680153436004\n"
     ]
    }
   ],
   "source": [
    "def clf():\n",
    "    return LogisticRegression(C=4, solver='lbfgs', max_iter=500)\n",
    "trained_clf, score = training(text_tf, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<159571x227490 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 4748387 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With Regex Tokenizer\n",
    "cv = CountVectorizer(lowercase=False, stop_words='english', tokenizer = simple.tokenize)\n",
    "text_cv = cv.fit_transform(training_text)\n",
    "\n",
    "training(text_cv, classifierLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With Porter Tokenizer\n",
    "cv = CountVectorizer(lowercase=False, stop_words='english', ngram_range = (1,1), tokenizer = simple.tokenize)\n",
    "text_cv = cv.fit_transform(training_text)\n",
    "\n",
    "training(text_cv, classifierLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = RegexpTokenizer(token_regex)\n",
    "\n",
    "# With Regex Tokenizer\n",
    "cv = CountVectorizer(lowercase=False, stop_words='english', ngram_range = (1,1), tokenizer = token.tokenize)\n",
    "text_cv = cv.fit_transform(training_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "tf = TfidfVectorizer(lowercase=False, stop_words='english', ngram_range = (1,1), tokenizer = token.tokenize)\n",
    "\n",
    "text_tf = tf.fit_transform(train['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_lemma_pos = CountVectorizer(lowercase=False, stop_words='english', ngram_range = (1,1), tokenizer = lemma_pos.tokenize)\n",
    "\n",
    "start = time.time()\n",
    "text_tf_lemma_pos = tf_lemma_pos.fit_transform(train['comment_text'])\n",
    "end = time.time()\n",
    "print (end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "tf = TfidfVectorizer(lowercase=False, stop_words='english', ngram_range = (1,1), tokenizer = token.tokenize)\n",
    "\n",
    "text_tf = tf.fit_transform(train['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_lemma_pos = CountVectorizer(lowercase=False, stop_words='english', ngram_range = (1,1), tokenizer = lemma_pos.tokenize)\n",
    "\n",
    "start = time.time()\n",
    "text_tf_lemma_pos = tf_lemma_pos.fit_transform(train['comment_text'])\n",
    "end = time.time()\n",
    "print (end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_lemma = CountVectorizer(lowercase=False, stop_words='english', ngram_range = (1,1), tokenizer = lemma.tokenize)\n",
    "\n",
    "start = time.time()\n",
    "text_tf_lemma =tf_lemma.fit_transform(train['comment_text'])\n",
    "end = time.time()\n",
    "print (end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tf_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tf_lemma_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifierMNB():\n",
    "    return MultinomialNB()\n",
    "\n",
    "def classifierLSVC():\n",
    "    return SVC(probability = True)\n",
    "\n",
    "def classifierLR():\n",
    "    return LogisticRegression(C=4, dual=True ,solver='liblinear')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"#1\")\n",
    "training(text_cv, classifierMNB)\n",
    "training(text_cv, classifierLR)\n",
    "\n",
    "print(\"#2\")\n",
    "training(text_cv_lemma, classifierMNB)\n",
    "training(text_cv_lemma, classifierLR)\n",
    "\n",
    "print(\"#3\")\n",
    "training(text_cv_lemma_pos, classifierMNB)\n",
    "training(text_cv_lemma_pos, classifierLR)\n",
    "\n",
    "print(\"#4\")\n",
    "training(text_tf, classifierMNB)\n",
    "training(text_tf, classifierLR)\n",
    "\n",
    "print(\"#5\")\n",
    "training(text_tf_lemma, classifierMNB)\n",
    "training(text_tf_lemma, classifierLR)\n",
    "\n",
    "print(\"#6\")\n",
    "training(text_tf_lemma_pos, classifierMNB)\n",
    "training(text_tf_lemma_pos, classifierLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"#1\")\n",
    "training(text_cv, classifierLSVC)\n",
    "\n",
    "# print(\"#2\")\n",
    "# training(text_cv_lemma, classifierLSVC)\n",
    "\n",
    "# print(\"#3\")\n",
    "# training(text_cv_lemma_pos, classifierLSVC)\n",
    "\n",
    "# print(\"#4\")\n",
    "# training(text_tf, classifierLSVC)\n",
    "\n",
    "# print(\"#5\")\n",
    "# training(text_tf_lemma, classifierLSVC)\n",
    "\n",
    "# print(\"#6\")\n",
    "# training(text_tf_lemma_pos, classifierLSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(X, TEST ,classifier):\n",
    "    test_cols = [ 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "    roc_aoc_scores = []\n",
    "    df = pd.DataFrame()\n",
    "    df['id'] = test['id']\n",
    "    \n",
    "    for eval_col in test_cols:\n",
    "        print(\"FIT \", eval_col)\n",
    "        y = train[eval_col]\n",
    "\n",
    "        clf = classifier().fit(X, y)\n",
    "        \n",
    "        predicted= clf.predict_proba(TEST)[:,1]\n",
    "        df[eval_col] = predicted\n",
    "\n",
    "    return df\n",
    "\n",
    "def calc_score(test_submission):\n",
    "    test_cols = [ 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "    roc_aoc_scores = []\n",
    "    selection = test_labels['toxic'] != -1\n",
    "    \n",
    "    test_dataset = test_labels[selection]\n",
    "    predicted_dataset = test_submission[selection]\n",
    "    \n",
    "    for eval_col in test_cols:\n",
    "        roc_aoc_scores.append(metrics.roc_auc_score(test_dataset[eval_col], predicted_dataset[eval_col]))\n",
    "    \n",
    "    print(roc_aoc_scores)\n",
    "    print(\"Score :\" , np.mean(np.array(roc_aoc_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_submission(text_counts_tf, text_counts_tf_test, classifierLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('submission_tfidf_lr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_score(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_score(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
